train{
    expname = dtu
    dataset_class = datasets.scene_dataset.SceneDataset
    model_class = model.network.VolSDFNetwork
    loss_class = model.loss.VolSDFLoss
    learning_rate = 5.0e-4
    num_pixels = 1024
    checkpoint_freq = 100
    plot_freq = 100
    split_n_pixels = 1000
    num_max_frame = 7 #TODO
    warmup_epoch = 500 #TODO
}
deform{
    position_lr_init = 0.00016 #TODO
    position_lr_final = 0.0000016 #TODO
    position_lr_delay_mult = 0.01 #TODO
    deform_lr_max_steps = 40_000 #TODO
}
plot{
    plot_nimgs = 1
    resolution = 100
    grid_boundary = [-1.5, 1.5]
}
loss{
    eikonal_weight = 0.1
    rgb_loss = torch.nn.L1Loss
}
dataset{
    data_dir = DTU_from_ypzhao_small_scale #TODO
    img_res = [1200, 1920] #TODO
}
model{
    feature_vector_size = 256
    scene_bounding_sphere = 3.0
    implicit_network
    {
        d_in = 3
        d_out = 1
        dims = [ 256, 256, 256, 256, 256, 256, 256, 256 ]
        geometric_init = True
        bias = 0.6
        skip_in = [4]
        weight_norm = True
        multires = 6
        sphere_scale = 20.0
    }
    rendering_network
    {
        mode = idr
        d_in = 9
        d_out = 3
        dims = [ 256, 256, 256, 256]
        weight_norm = True
        multires_view = 4
    }
    density
    {
        params_init{
            beta = 0.1
        }
        beta_min = 0.0001
    }
    ray_sampler
    {
        near = 0.0
        N_samples = 64
        N_samples_eval = 128
        N_samples_extra = 32
        eps = 0.1
        beta_iters = 10
        max_total_iters = 5
    }
}
